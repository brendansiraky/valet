---
phase: 05-execution-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/db/schema/pipeline-runs.ts
  - app/db/index.ts
  - app/services/run-emitter.server.ts
  - app/services/pipeline-executor.server.ts
autonomous: true

must_haves:
  truths:
    - "Pipeline run state can be persisted to database"
    - "Individual agent step results are tracked"
    - "Events can be emitted during pipeline execution"
    - "Executor can run agents sequentially passing output forward"
  artifacts:
    - path: "app/db/schema/pipeline-runs.ts"
      provides: "Run and step tracking tables"
      exports: ["pipelineRuns", "pipelineRunSteps", "PipelineRun", "PipelineRunStep"]
    - path: "app/services/run-emitter.server.ts"
      provides: "EventEmitter singleton for SSE bridge"
      exports: ["runEmitter"]
    - path: "app/services/pipeline-executor.server.ts"
      provides: "Sequential pipeline execution with streaming events"
      exports: ["executePipeline", "PipelineStep"]
  key_links:
    - from: "app/services/pipeline-executor.server.ts"
      to: "app/services/run-emitter.server.ts"
      via: "emitter.emit for real-time events"
      pattern: "runEmitter\\.emit"
    - from: "app/services/pipeline-executor.server.ts"
      to: "app/services/agent-runner.server.ts"
      via: "runAgent calls for each step"
      pattern: "runAgent"
    - from: "app/services/pipeline-executor.server.ts"
      to: "app/db/schema/pipeline-runs.ts"
      via: "database updates for step status"
      pattern: "db\\.(update|insert).*pipelineRun"
---

<objective>
Create the foundational infrastructure for pipeline execution: database schema for tracking runs and steps, an EventEmitter bridge for real-time streaming, and the core executor service that runs agents sequentially.

Purpose: This establishes the data model and execution logic that all subsequent execution features build upon.
Output: Database tables for run tracking, event emitter for SSE bridge, pipeline executor service.
</objective>

<execution_context>
@/Users/brendan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/brendan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-execution-engine/05-RESEARCH.md

@app/db/schema/pipelines.ts
@app/services/agent-runner.server.ts
@app/services/capabilities/text-generation.server.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pipeline runs database schema</name>
  <files>app/db/schema/pipeline-runs.ts, app/db/index.ts</files>
  <action>
Create the database schema for tracking pipeline execution runs and individual agent steps.

In `app/db/schema/pipeline-runs.ts`:
1. Create `pipelineRuns` table with fields:
   - id (text, UUID primary key)
   - pipelineId (text, FK to pipelines.id, cascade delete)
   - userId (text, FK to users.id, cascade delete)
   - status (text: 'pending' | 'running' | 'completed' | 'failed')
   - input (text, initial input for first agent)
   - variables (jsonb, Record<string, string> for template variables, nullable)
   - finalOutput (text, nullable, stores final agent output)
   - error (text, nullable, error message if failed)
   - createdAt (timestamp, default now)
   - completedAt (timestamp, nullable)
   - Indexes on userId and pipelineId

2. Create `pipelineRunSteps` table with fields:
   - id (text, UUID primary key)
   - runId (text, FK to pipelineRuns.id, cascade delete)
   - agentId (text, the agent being executed)
   - stepOrder (integer, position in pipeline)
   - status (text: 'pending' | 'running' | 'completed' | 'failed')
   - input (text, nullable, input to this agent)
   - output (text, nullable, output from this agent)
   - error (text, nullable, error message if step failed)
   - startedAt (timestamp, nullable)
   - completedAt (timestamp, nullable)
   - Index on runId

3. Export types: PipelineRun, NewPipelineRun, PipelineRunStep, NewPipelineRunStep

In `app/db/index.ts`:
- Add export for pipeline-runs schema

Run `npx drizzle-kit generate` to create migration.
  </action>
  <verify>
`npx tsc --noEmit` passes. Migration file created in drizzle/ folder.
  </verify>
  <done>
Pipeline runs and steps tables defined with proper FKs, indexes, and type exports. Migration generated.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create run emitter for SSE bridge</name>
  <files>app/services/run-emitter.server.ts</files>
  <action>
Create a singleton EventEmitter that bridges pipeline execution events to SSE endpoints.

In `app/services/run-emitter.server.ts`:
1. Import EventEmitter from 'events'
2. Create and export `runEmitter` as a singleton EventEmitter
3. Set max listeners to 100 (allows many concurrent runs)
4. Define and export RunEvent type:
   ```typescript
   export type RunEvent =
     | { type: 'step_start'; stepIndex: number; agentName: string }
     | { type: 'text_delta'; stepIndex: number; text: string }
     | { type: 'step_complete'; stepIndex: number; output: string }
     | { type: 'pipeline_complete'; finalOutput: string }
     | { type: 'error'; stepIndex?: number; message: string };
   ```
5. Events are namespaced by runId: `run:${runId}`

This emitter is a global singleton - survives across requests and allows the SSE endpoint to listen for events from the executor.
  </action>
  <verify>
`npx tsc --noEmit` passes. File exports runEmitter and RunEvent type.
  </verify>
  <done>
EventEmitter singleton created for bridging execution events to SSE.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create pipeline executor service</name>
  <files>app/services/pipeline-executor.server.ts</files>
  <action>
Create the core pipeline execution service that runs agents sequentially with streaming events.

In `app/services/pipeline-executor.server.ts`:
1. Define PipelineStep interface:
   ```typescript
   export interface PipelineStep {
     agentId: string;
     agentName: string;
     instructions: string;
     order: number;
   }
   ```

2. Define ExecutePipelineParams:
   ```typescript
   export interface ExecutePipelineParams {
     runId: string;
     steps: PipelineStep[];
     initialInput: string;
     encryptedApiKey: string;
     model: string;
     variables?: Record<string, string>;
   }
   ```

3. Implement `executePipeline` function:
   - Import runEmitter from run-emitter.server.ts
   - Import db and pipelineRunSteps, pipelineRuns from db
   - Import createAnthropicClient from anthropic.server.ts
   - For each step in order:
     a. Update step status to 'running' in DB
     b. Emit 'step_start' event with stepIndex and agentName
     c. Substitute variables in instructions (replace {{varName}} with value)
     d. Use Anthropic SDK `.stream()` method (not non-streaming) for real-time output:
        ```typescript
        const stream = client.messages.stream({
          model,
          max_tokens: 4096,
          system: substitutedInstructions,
          messages: [{ role: 'user', content: currentInput }],
        });

        let fullOutput = '';
        stream.on('text', (text) => {
          fullOutput += text;
          runEmitter.emit(`run:${runId}`, {
            type: 'text_delta',
            stepIndex: step.order,
            text,
          });
        });

        await stream.finalMessage();
        ```
     e. Update step with output, status 'completed', completedAt
     f. Emit 'step_complete' event
     g. Pass output as input to next step
   - After all steps complete:
     a. Update run with finalOutput, status 'completed', completedAt
     b. Emit 'pipeline_complete' event
   - On any error:
     a. Update step and run with error, status 'failed'
     b. Emit 'error' event with message
     c. Stop execution (do not continue to next steps)
  </action>
  <verify>
`npx tsc --noEmit` passes. Function executePipeline is exported and uses streaming API.
  </verify>
  <done>
Pipeline executor service runs agents sequentially, streams output via events, persists state to DB, handles errors.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes without errors
2. `npx drizzle-kit generate` creates migration for new tables
3. All three files exist and export their expected symbols
</verification>

<success_criteria>
- pipelineRuns and pipelineRunSteps tables defined with proper types
- Migration file generated for new schema
- runEmitter singleton created with RunEvent type
- executePipeline function implements sequential execution with streaming
- Variable substitution works for template variables
- Errors properly caught and recorded
</success_criteria>

<output>
After completion, create `.planning/phases/05-execution-engine/05-01-SUMMARY.md`
</output>
