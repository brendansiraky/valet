---
phase: 05-execution-engine
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - app/services/job-queue.server.ts
  - app/routes/api.pipeline.$pipelineId.run.ts
  - app/routes/api.pipeline.run.$runId.stream.ts
  - app/routes.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "User can trigger pipeline execution via API"
    - "Pipeline runs are queued for reliable processing"
    - "User can receive real-time streaming updates via SSE"
    - "Job queue handles retries on failure"
  artifacts:
    - path: "app/services/job-queue.server.ts"
      provides: "pg-boss job queue singleton and worker registration"
      exports: ["getJobQueue", "registerPipelineWorker"]
    - path: "app/routes/api.pipeline.$pipelineId.run.ts"
      provides: "POST endpoint to start pipeline execution"
      exports: ["action"]
    - path: "app/routes/api.pipeline.run.$runId.stream.ts"
      provides: "SSE endpoint for real-time run updates"
      exports: ["loader"]
  key_links:
    - from: "app/routes/api.pipeline.$pipelineId.run.ts"
      to: "app/services/job-queue.server.ts"
      via: "queue.send to enqueue pipeline job"
      pattern: "queue\\.send.*pipeline-run"
    - from: "app/routes/api.pipeline.run.$runId.stream.ts"
      to: "app/services/run-emitter.server.ts"
      via: "runEmitter.on to listen for events"
      pattern: "runEmitter\\.on"
    - from: "app/services/job-queue.server.ts"
      to: "app/services/pipeline-executor.server.ts"
      via: "worker calls executePipeline"
      pattern: "executePipeline"
---

<objective>
Set up the job queue for reliable pipeline execution and create the API endpoints for starting runs and streaming progress via Server-Sent Events.

Purpose: This enables users to trigger pipeline execution and receive real-time updates without polling.
Output: pg-boss job queue, start execution API, SSE streaming endpoint.
</objective>

<execution_context>
@/Users/brendan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/brendan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-execution-engine/05-RESEARCH.md
@.planning/phases/05-execution-engine/05-01-SUMMARY.md

@app/db/schema/pipeline-runs.ts
@app/services/run-emitter.server.ts
@app/services/pipeline-executor.server.ts
@app/routes/api.pipelines.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install pg-boss and remix-utils, create job queue service</name>
  <files>package.json, app/services/job-queue.server.ts</files>
  <action>
Install dependencies and create the pg-boss job queue singleton with pipeline worker.

1. Install dependencies:
   ```bash
   npm install pg-boss remix-utils
   ```

2. Create `app/services/job-queue.server.ts`:
   - Import PgBoss from 'pg-boss'
   - Import executePipeline and PipelineStep from pipeline-executor.server.ts
   - Import db, pipelineRuns, pipelineRunSteps, agents, pipelines from db
   - Import eq from drizzle-orm
   - Import decrypt from encryption.server.ts
   - Import apiKeys from db/schema/api-keys.ts

   Define job data interface:
   ```typescript
   interface PipelineRunJob {
     runId: string;
     pipelineId: string;
     userId: string;
     input: string;
     variables?: Record<string, string>;
   }
   ```

   Create singleton pattern:
   ```typescript
   let boss: PgBoss | null = null;
   let isWorkerRegistered = false;

   export async function getJobQueue(): Promise<PgBoss> {
     if (boss) return boss;

     boss = new PgBoss(process.env.DATABASE_URL!);
     boss.on('error', (err) => console.error('pg-boss error:', err));

     await boss.start();
     return boss;
   }
   ```

   Create worker registration (call once at startup):
   ```typescript
   export async function registerPipelineWorker() {
     if (isWorkerRegistered) return;

     const queue = await getJobQueue();

     await queue.work('pipeline-run', async ([job]) => {
       const { runId, pipelineId, userId, input, variables } = job.data as PipelineRunJob;

       // Update run status to 'running'
       await db.update(pipelineRuns)
         .set({ status: 'running' })
         .where(eq(pipelineRuns.id, runId));

       // Load pipeline flow data to get steps
       const [pipeline] = await db.select()
         .from(pipelines)
         .where(eq(pipelines.id, pipelineId));

       if (!pipeline) {
         await db.update(pipelineRuns)
           .set({ status: 'failed', error: 'Pipeline not found' })
           .where(eq(pipelineRuns.id, runId));
         return;
       }

       // Get user's API key and model
       const [apiKey] = await db.select()
         .from(apiKeys)
         .where(eq(apiKeys.userId, userId));

       if (!apiKey) {
         await db.update(pipelineRuns)
           .set({ status: 'failed', error: 'API key not configured' })
           .where(eq(pipelineRuns.id, runId));
         return;
       }

       // Extract steps from flow data (nodes in topological order by edges)
       const flowData = pipeline.flowData as { nodes: any[]; edges: any[] };
       const steps = await buildStepsFromFlow(flowData, db, agents);

       // Create step records
       for (const step of steps) {
         await db.insert(pipelineRunSteps).values({
           runId,
           agentId: step.agentId,
           stepOrder: step.order,
           status: 'pending',
         });
       }

       // Execute pipeline
       await executePipeline({
         runId,
         steps,
         initialInput: input,
         encryptedApiKey: apiKey.encryptedKey,
         model: apiKey.model,
         variables,
       });
     });

     isWorkerRegistered = true;
   }

   // Helper to build steps from React Flow graph (topological sort by edges)
   async function buildStepsFromFlow(
     flowData: { nodes: any[]; edges: any[] },
     db: any,
     agents: any
   ): Promise<PipelineStep[]> {
     const { nodes, edges } = flowData;

     // Build adjacency list and in-degree map
     const inDegree = new Map<string, number>();
     const adjacency = new Map<string, string[]>();

     nodes.forEach(node => {
       inDegree.set(node.id, 0);
       adjacency.set(node.id, []);
     });

     edges.forEach(edge => {
       inDegree.set(edge.target, (inDegree.get(edge.target) || 0) + 1);
       adjacency.get(edge.source)?.push(edge.target);
     });

     // Kahn's algorithm for topological sort
     const queue = nodes.filter(n => inDegree.get(n.id) === 0).map(n => n.id);
     const sorted: string[] = [];

     while (queue.length > 0) {
       const nodeId = queue.shift()!;
       sorted.push(nodeId);

       for (const neighbor of adjacency.get(nodeId) || []) {
         inDegree.set(neighbor, (inDegree.get(neighbor) || 0) - 1);
         if (inDegree.get(neighbor) === 0) {
           queue.push(neighbor);
         }
       }
     }

     // Map to PipelineStep with agent details
     const steps: PipelineStep[] = [];
     for (let i = 0; i < sorted.length; i++) {
       const node = nodes.find(n => n.id === sorted[i]);
       if (!node || node.type !== 'agent') continue;

       const agentId = node.data.agentId;
       const [agent] = await db.select().from(agents).where(eq(agents.id, agentId));

       if (agent) {
         steps.push({
           agentId: agent.id,
           agentName: agent.name,
           instructions: agent.instructions,
           order: steps.length,
         });
       }
     }

     return steps;
   }
   ```

Note: pg-boss automatically creates its schema tables on first start.
  </action>
  <verify>
`npm install` completes. `npx tsc --noEmit` passes. pg-boss and remix-utils in package.json dependencies.
  </verify>
  <done>
pg-boss job queue singleton created with pipeline-run worker that executes pipelines from flow data.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create pipeline run API endpoint</name>
  <files>app/routes/api.pipeline.$pipelineId.run.ts, app/routes.ts</files>
  <action>
Create POST endpoint that starts a pipeline execution by creating a run record and queueing a job.

In `app/routes/api.pipeline.$pipelineId.run.ts`:
1. Import dependencies:
   - getSession from session.server.ts
   - db, pipelineRuns, pipelines from db
   - eq, and from drizzle-orm
   - getJobQueue, registerPipelineWorker from job-queue.server.ts
   - json from react-router

2. Create action function:
   ```typescript
   export async function action({ request, params }: ActionFunctionArgs) {
     const session = await getSession(request.headers.get('Cookie'));
     const userId = session.get('userId');

     if (!userId) {
       return json({ error: 'Unauthorized' }, { status: 401 });
     }

     const pipelineId = params.pipelineId;
     if (!pipelineId) {
       return json({ error: 'Pipeline ID required' }, { status: 400 });
     }

     // Verify pipeline exists and belongs to user
     const [pipeline] = await db.select()
       .from(pipelines)
       .where(and(
         eq(pipelines.id, pipelineId),
         eq(pipelines.userId, userId)
       ));

     if (!pipeline) {
       return json({ error: 'Pipeline not found' }, { status: 404 });
     }

     // Parse request body
     const formData = await request.formData();
     const input = formData.get('input') as string || '';
     const variablesJson = formData.get('variables') as string;
     const variables = variablesJson ? JSON.parse(variablesJson) : undefined;

     // Create run record
     const [run] = await db.insert(pipelineRuns).values({
       pipelineId,
       userId,
       input,
       variables,
       status: 'pending',
     }).returning();

     // Ensure worker is registered and queue job
     await registerPipelineWorker();
     const queue = await getJobQueue();

     await queue.send('pipeline-run', {
       runId: run.id,
       pipelineId,
       userId,
       input,
       variables,
     }, {
       retryLimit: 2,
       retryDelay: 5000,
     });

     return json({ runId: run.id });
   }
   ```

In `app/routes.ts`:
- Add route entry: `route("api/pipeline/:pipelineId/run", "routes/api.pipeline.$pipelineId.run.ts")`
  </action>
  <verify>
`npx tsc --noEmit` passes. Route registered in routes.ts.
  </verify>
  <done>
POST /api/pipeline/:pipelineId/run endpoint creates run record and queues job for execution.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create SSE streaming endpoint</name>
  <files>app/routes/api.pipeline.run.$runId.stream.ts, app/routes.ts</files>
  <action>
Create SSE endpoint that streams real-time execution events to the client.

In `app/routes/api.pipeline.run.$runId.stream.ts`:
1. Import dependencies:
   - eventStream from 'remix-utils/sse/server'
   - runEmitter, RunEvent from run-emitter.server.ts
   - getSession from session.server.ts
   - db, pipelineRuns from db
   - eq, and from drizzle-orm

2. Create loader function:
   ```typescript
   export async function loader({ request, params }: LoaderFunctionArgs) {
     const session = await getSession(request.headers.get('Cookie'));
     const userId = session.get('userId');

     if (!userId) {
       return new Response('Unauthorized', { status: 401 });
     }

     const runId = params.runId;
     if (!runId) {
       return new Response('Run ID required', { status: 400 });
     }

     // Verify run exists and belongs to user
     const [run] = await db.select()
       .from(pipelineRuns)
       .where(and(
         eq(pipelineRuns.id, runId),
         eq(pipelineRuns.userId, userId)
       ));

     if (!run) {
       return new Response('Run not found', { status: 404 });
     }

     return eventStream(request.signal, function setup(send) {
       function handleEvent(data: RunEvent) {
         send({ event: 'update', data: JSON.stringify(data) });
       }

       runEmitter.on(`run:${runId}`, handleEvent);

       // Send initial status if run already started/completed
       if (run.status !== 'pending') {
         send({
           event: 'update',
           data: JSON.stringify({ type: 'status', status: run.status })
         });
       }

       return function cleanup() {
         runEmitter.off(`run:${runId}`, handleEvent);
       };
     });
   }
   ```

In `app/routes.ts`:
- Add route entry: `route("api/pipeline/run/:runId/stream", "routes/api.pipeline.run.$runId.stream.ts")`
  </action>
  <verify>
`npx tsc --noEmit` passes. Route registered in routes.ts.
  </verify>
  <done>
SSE endpoint at /api/pipeline/run/:runId/stream delivers real-time execution events to clients.
  </done>
</task>

</tasks>

<verification>
1. `npm install` completes successfully with pg-boss and remix-utils
2. `npx tsc --noEmit` passes without errors
3. Both API routes registered in routes.ts
4. Manual test: POST to /api/pipeline/:id/run returns runId
</verification>

<success_criteria>
- pg-boss and remix-utils installed as dependencies
- Job queue singleton initializes and registers pipeline worker
- POST /api/pipeline/:pipelineId/run creates run and queues job
- GET /api/pipeline/run/:runId/stream returns SSE response
- Worker executes pipelines using topological sort of flow graph
- Retry logic configured (2 retries, 5s delay)
</success_criteria>

<output>
After completion, create `.planning/phases/05-execution-engine/05-02-SUMMARY.md`
</output>
