---
phase: 14-artifact-storage
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/db/schema/pipeline-runs.ts
  - app/services/pipeline-executor.server.ts
  - app/lib/pricing.ts
autonomous: true

must_haves:
  truths:
    - "Completed pipeline runs store structured artifact data in database"
    - "Artifact data includes step-level outputs and final output"
    - "Metadata (model, tokens, cost) is stored at run completion time"
  artifacts:
    - path: "app/db/schema/pipeline-runs.ts"
      provides: "ArtifactOutput type and extended columns"
      contains: "artifactData"
    - path: "app/services/pipeline-executor.server.ts"
      provides: "Artifact storage on completion"
      contains: "artifactData"
  key_links:
    - from: "app/services/pipeline-executor.server.ts"
      to: "app/db/schema/pipeline-runs.ts"
      via: "db.update with artifactData"
      pattern: "artifactData.*steps"
---

<objective>
Extend pipeline_runs schema to store structured artifact data and update executor to persist artifacts on completion.

Purpose: Enable persistent storage of pipeline outputs with metadata for later viewing.
Output: Extended schema with artifact columns, executor writes structured data on completion.
</objective>

<execution_context>
@/Users/brendan/.claude/get-shit-done/workflows/execute-plan.md
@/Users/brendan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/14-artifact-storage/14-RESEARCH.md
@app/db/schema/pipeline-runs.ts
@app/services/pipeline-executor.server.ts
@app/lib/pricing.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend pipeline_runs schema with artifact columns</name>
  <files>app/db/schema/pipeline-runs.ts, app/lib/pricing.ts</files>
  <action>
  Add ArtifactOutput interface and extend pipelineRuns table with new columns:

  1. Add ArtifactOutput interface at top of file:
  ```typescript
  export interface ArtifactOutput {
    steps: Array<{
      agentId: string;
      agentName: string;
      output: string;
      stepOrder: number;
    }>;
    finalOutput: string;
  }
  ```

  2. Add columns to pipelineRuns table (after existing columns, before error):
  - `artifactData: jsonb("artifact_data").$type<ArtifactOutput>()` - nullable for backward compat
  - `model: text("model")` - nullable
  - `inputTokens: integer("input_tokens")` - nullable
  - `outputTokens: integer("output_tokens")` - nullable
  - `cost: numeric("cost", { precision: 10, scale: 6 })` - nullable

  Import `numeric` from drizzle-orm/pg-core.

  3. Update MODEL_PRICING in app/lib/pricing.ts to include OpenAI models:
  ```typescript
  // Anthropic models
  "claude-opus-4-5-20251101": { input: 5, output: 25 },
  "claude-sonnet-4-5-20250929": { input: 3, output: 15 },
  "claude-haiku-4-5-20251001": { input: 1, output: 5 },
  // OpenAI models
  "gpt-4o": { input: 2.5, output: 10 },
  "gpt-4o-mini": { input: 0.15, output: 0.6 },
  ```

  4. Run migration: `npm run db:push`
  </action>
  <verify>
  - `npm run typecheck` passes
  - `npm run db:push` completes without error
  - Database shows new columns in pipeline_runs table
  </verify>
  <done>
  - ArtifactOutput type exported from schema
  - pipeline_runs table has artifactData, model, inputTokens, outputTokens, cost columns
  - OpenAI models have pricing data
  </done>
</task>

<task type="auto">
  <name>Task 2: Update executor to store artifact data on completion</name>
  <files>app/services/pipeline-executor.server.ts</files>
  <action>
  Modify executePipeline to store structured artifact data when pipeline completes:

  1. Import calculateCost from ~/lib/pricing and ArtifactOutput from schema:
  ```typescript
  import { calculateCost } from "~/lib/pricing";
  import type { ArtifactOutput } from "~/db/schema/pipeline-runs";
  ```

  2. Track step outputs during execution. After the for loop, build artifact data:
  - Create a Map to store step outputs as they complete
  - After each step completes (where output is stored), also store in the Map
  - Example: Add `const stepOutputs = new Map<number, { agentId: string; agentName: string; output: string }>();`
  - After updating step status to completed, also: `stepOutputs.set(step.order, { agentId: step.agentId, agentName: step.agentName, output: result.content });`

  3. On successful completion (in the "All steps complete" section), build and store artifact:
  ```typescript
  const artifactData: ArtifactOutput = {
    steps: Array.from(stepOutputs.entries())
      .sort(([a], [b]) => a - b)
      .map(([stepOrder, data]) => ({
        ...data,
        stepOrder,
      })),
    finalOutput: currentInput,
  };

  const cost = calculateCost(model, usage.totalInputTokens, usage.totalOutputTokens);

  await db
    .update(pipelineRuns)
    .set({
      status: "completed",
      finalOutput: currentInput, // Keep for backward compat
      artifactData,
      model,
      inputTokens: usage.totalInputTokens,
      outputTokens: usage.totalOutputTokens,
      cost: cost.toString(),
      completedAt: new Date(),
    })
    .where(eq(pipelineRuns.id, runId));
  ```

  Note: Keep existing finalOutput for backward compatibility with any code that reads it.
  </action>
  <verify>
  - `npm run typecheck` passes
  - Run a test pipeline, check database for populated artifact columns
  - artifactData contains steps array with agentId, agentName, output, stepOrder
  - model, inputTokens, outputTokens, cost columns are populated
  </verify>
  <done>
  - Executor stores structured artifactData on completion
  - Metadata (model, tokens, cost) stored alongside artifact
  - Existing finalOutput still populated for backward compatibility
  </done>
</task>

</tasks>

<verification>
After both tasks:
1. `npm run typecheck` passes
2. Run a pipeline through the UI
3. Query database: `SELECT id, artifact_data, model, input_tokens, output_tokens, cost FROM pipeline_runs WHERE status = 'completed' ORDER BY completed_at DESC LIMIT 1;`
4. Verify artifact_data contains steps array with expected structure
5. Verify metadata columns are populated
</verification>

<success_criteria>
- [ ] ArtifactOutput type defined and exported
- [ ] pipeline_runs has artifactData JSONB column
- [ ] pipeline_runs has model, inputTokens, outputTokens, cost columns
- [ ] OpenAI models have pricing in MODEL_PRICING
- [ ] Executor stores structured artifact on completion
- [ ] Metadata stored at completion time (not calculated on read)
- [ ] Backward compatibility maintained (finalOutput still populated)
</success_criteria>

<output>
After completion, create `.planning/phases/14-artifact-storage/14-01-SUMMARY.md`
</output>
